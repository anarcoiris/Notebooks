{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Document Processing Pipeline\n",
    "\n",
    "**Project**: Examn Xterminator  \n",
    "**Technologies**: OpenAI API, PyPDF2, LaTeX, Python  \n",
    "**Source**: [https://github.com/anarcoiris/Examn_Xterminator](https://github.com/anarcoiris/Examn_Xterminator)\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "End-to-end pipeline for extracting, analyzing, and solving exam questions from PDFs using Large Language Models and automated LaTeX generation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\n\n# Try to add Examn_Xterminator to path (repository code available for reference only)\ntry:\n    repo_path = Path('Examn_Xterminator').resolve()\n    if repo_path.exists():\n        sys.path.insert(0, str(repo_path))\n        print(\"\u2713 Repository code loaded\")\n    else:\n        print(\"\u2139 Note: Repository code not found. Using standalone demo implementations.\")\nexcept Exception as e:\n    print(f\"\u2139 Note: Repository import skipped - using demo code ({e})\")\n\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"\u2713 Document processing environment ready\")\nprint(\"\\n\ud83d\udcdd Execution Note:\")\nprint(\"   This notebook demonstrates PDF processing and NLP techniques.\")\nprint(\"   Full production code available at: https://github.com/anarcoiris/Examn_Xterminator\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenAI API Integration\n",
    "\n",
    "### Use Cases\n",
    "- **Problem Analysis**: Difficulty classification, topic identification\n",
    "- **Solution Generation**: Step-by-step explanations\n",
    "- **Quality Check**: Validate extracted content\n",
    "\n",
    "### Cost Optimization\n",
    "- Batch requests to minimize API calls\n",
    "- Cache responses for duplicate questions\n",
    "- Token counting before submission\n",
    "- Rate limiting to avoid throttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost tracking for API usage\n",
    "class APIUsageTracker:\n",
    "    def __init__(self, cost_per_1k_tokens=0.002):\n",
    "        self.total_tokens = 0\n",
    "        self.total_requests = 0\n",
    "        self.cost_per_1k = cost_per_1k_tokens\n",
    "    \n",
    "    def log_request(self, prompt_tokens, completion_tokens):\n",
    "        total = prompt_tokens + completion_tokens\n",
    "        self.total_tokens += total\n",
    "        self.total_requests += 1\n",
    "        return self.get_cost()\n",
    "    \n",
    "    def get_cost(self):\n",
    "        return (self.total_tokens / 1000) * self.cost_per_1k\n",
    "    \n",
    "    def summary(self):\n",
    "        return {\n",
    "            'total_tokens': self.total_tokens,\n",
    "            'total_requests': self.total_requests,\n",
    "            'total_cost': self.get_cost(),\n",
    "            'avg_tokens_per_request': self.total_tokens / max(self.total_requests, 1)\n",
    "        }\n",
    "\n",
    "# Demo\n",
    "tracker = APIUsageTracker()\n",
    "tracker.log_request(150, 300)  # Question analysis\n",
    "tracker.log_request(200, 500)  # Solution generation\n",
    "\n",
    "summary = tracker.summary()\n",
    "print(\"API Usage Summary:\")\n",
    "print(f\"  Total requests: {summary['total_requests']}\")\n",
    "print(f\"  Total tokens: {summary['total_tokens']:,}\")\n",
    "print(f\"  Estimated cost: ${summary['total_cost']:.4f}\")\n",
    "print(f\"  Avg tokens/request: {summary['avg_tokens_per_request']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content Clustering & Analysis\n",
    "\n",
    "### Problem Similarity Detection\n",
    "- **TF-IDF Vectorization**: Convert text to numerical features\n",
    "- **Cosine Similarity**: Measure problem similarity\n",
    "- **K-Means Clustering**: Group similar questions\n",
    "\n",
    "### Applications\n",
    "- Identify duplicate problems\n",
    "- Generate topic-based study guides\n",
    "- Suggest related practice problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample exam questions\n",
    "questions = [\n",
    "    \"Calculate the derivative of f(x) = x^2 + 3x + 2\",\n",
    "    \"Find the integral of g(x) = 2x + 5\",\n",
    "    \"Determine the limit as x approaches 0 of sin(x)/x\",\n",
    "    \"Compute the derivative of h(x) = e^x * cos(x)\",\n",
    "    \"Evaluate the definite integral from 0 to 1 of x^2 dx\",\n",
    "    \"Calculate lim(x\u2192\u221e) of (1 + 1/x)^x\",\n",
    "]\n",
    "\n",
    "# Vectorize questions\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(questions)\n",
    "\n",
    "# Cluster questions\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "print(\"Question Clustering Results:\")\n",
    "for i in range(n_clusters):\n",
    "    cluster_questions = [q for j, q in enumerate(questions) if clusters[j] == i]\n",
    "    print(f\"\\nCluster {i+1} (Topic):\")\n",
    "    for q in cluster_questions:\n",
    "        print(f\"  - {q}\")\n",
    "\n",
    "# Similarity matrix\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "print(f\"\\nSimilarity Matrix Shape: {similarity_matrix.shape}\")\n",
    "print(f\"Most similar pair: Q{np.unravel_index(np.argsort(similarity_matrix, axis=None)[-2], similarity_matrix.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LaTeX Document Generation\n",
    "\n",
    "### Automated Typesetting\n",
    "- **Template System**: Reusable document structures\n",
    "- **Math Rendering**: Proper equation formatting\n",
    "- **Bibliography**: Auto-generate citations\n",
    "\n",
    "### Output Formats\n",
    "- Study guides\n",
    "- Solution manuals\n",
    "- Practice exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaTeX generator (simplified)\n",
    "def generate_latex_exam(title, questions_with_solutions):\n",
    "    \"\"\"\n",
    "    Generate LaTeX document from exam questions.\n",
    "    \"\"\"\n",
    "    latex = r\"\"\"\n",
    "\\documentclass[12pt]{article}\n",
    "\\usepackage{amsmath, amssymb}\n",
    "\\usepackage{geometry}\n",
    "\\geometry{margin=1in}\n",
    "\n",
    "\\title{\"\"\" + title + r\"\"\"}\n",
    "\\date{\\today}\n",
    "\n",
    "\\begin{document}\n",
    "\\maketitle\n",
    "\n",
    "\\section{Problems}\n",
    "\"\"\"\n",
    "    \n",
    "    for i, (question, solution) in enumerate(questions_with_solutions, 1):\n",
    "        latex += f\"\"\"\n",
    "\\subsection{{Problem {i}}}\n",
    "{question}\n",
    "\n",
    "\\textbf{{Solution:}}\n",
    "{solution}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    latex += r\"\"\"\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    return latex\n",
    "\n",
    "# Demo\n",
    "exam_data = [\n",
    "    (\"Calculate $\\\\frac{d}{dx}(x^2 + 3x + 2)$\", \"$2x + 3$\"),\n",
    "    (\"Evaluate $\\\\int_0^1 x^2 dx$\", \"$\\\\frac{1}{3}$\"),\n",
    "]\n",
    "\n",
    "latex_output = generate_latex_exam(\"Calculus Practice Exam\", exam_data)\n",
    "print(\"Generated LaTeX:\")\n",
    "print(latex_output[:500] + \"...\")\n",
    "print(f\"\\nTotal length: {len(latex_output)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Technical Achievements\n",
    "\u2705 PDF extraction with error handling  \n",
    "\u2705 OpenAI API integration with cost tracking  \n",
    "\u2705 NLP-based content clustering  \n",
    "\u2705 Automated LaTeX generation  \n",
    "\u2705 End-to-end ETL pipeline  \n",
    "\n",
    "### Skills\n",
    "**Data Engineering**: PDF parsing, text normalization, ETL design  \n",
    "**API Integration**: OpenAI, rate limiting, cost optimization  \n",
    "**NLP**: TF-IDF, clustering, similarity detection  \n",
    "**Document Generation**: LaTeX, templating\n",
    "\n",
    "## References\n",
    "- **Repository**: https://github.com/anarcoiris/Examn_Xterminator\n",
    "- **Technologies**: Python, PyPDF2, OpenAI API, LaTeX, scikit-learn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}