{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcca Data Engineering & Data Science Portfolio\n",
    "\n",
    "**Author**: Portfolio Showcase  \n",
    "**Last Updated**: 2025-11-29  \n",
    "**Target Roles**: Data Engineer | Data Scientist | Data Architect  \n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfaf Overview\n",
    "\n",
    "This portfolio demonstrates **production-grade** data engineering, machine learning, and distributed systems expertise through real-world projects. All notebooks are executable and showcase end-to-end implementation from data ingestion to deployment.\n",
    "\n",
    "### \ud83d\udd11 Key Competencies\n",
    "\n",
    "\u2705 **Data Engineering**: ETL pipelines, streaming (Kafka), batch processing (PySpark)  \n",
    "\u2705 **Machine Learning**: Deep learning (PyTorch), NLP, time series forecasting  \n",
    "\u2705 **Cloud Architecture**: Azure integration, Data Lake, blob storage  \n",
    "\u2705 **Distributed Systems**: Hadoop, HDFS, Docker, containerization  \n",
    "\u2705 **Production Patterns**: Monitoring, error handling, cost optimization  \n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Portfolio Structure\n",
    "\n",
    "### \ud83e\udd16 Machine Learning & Finance\n",
    "\n",
    "#### [ML_Finance/BitCorn_Farmer/bitcorn_farmer_demo.ipynb](ML_Finance/BitCorn_Farmer/bitcorn_farmer_demo.ipynb)\n",
    "**BitCorn Farmer: RL Trading Agent & Oracle**\n",
    "\n",
    "- **Pipeline**: SQLite \u2192 LSTM Oracle \u2192 PPO Agent\n",
    "- **Technologies**: PyTorch, PPO (RL), LSTM, SQLite\n",
    "- **Highlights**: \n",
    "  - Autoregressive price forecasting (The Oracle)\n",
    "  - Hybrid action space RL agent (Discrete + Continuous)\n",
    "  - Feature recalculation to prevent data leakage\n",
    "  - Interactive demo with confidence intervals\n",
    "- **Skills**: Reinforcement Learning, Financial Modeling, Deep Learning\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfae Game Theory & Reinforcement Learning\n",
    "\n",
    "#### [ML_GameTheory/Poker_DeepRL.ipynb](ML_GameTheory/Poker_DeepRL.ipynb)\n",
    "**Poker Strategy Analysis with Deep RL**\n",
    "\n",
    "- **Approach**: Game-theoretic AI, Nash equilibrium approximation\n",
    "- **Technologies**: Python, Deep Learning, Monte Carlo Simulation\n",
    "- **Highlights**:\n",
    "  - Self-attention for state representation\n",
    "  - Counterfactual regret minimization\n",
    "  - Monte Carlo equity calculation\n",
    "  - GTO strategy implementation\n",
    "- **Skills**: Reinforcement Learning, Game Theory, Statistical Simulation\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83e\udde0 NLP & Transformers\n",
    "\n",
    "#### [NLP/Custom_Transformer_Implementation.ipynb](NLP/Custom_Transformer_Implementation.ipynb)\n",
    "**Transformer Architecture from Scratch**\n",
    "\n",
    "- **Implementation**: Character-level language model (10M parameters)\n",
    "- **Technologies**: Python, NumPy, Deep Learning\n",
    "- **Highlights**:\n",
    "  - Self-attention mechanism with causal masking\n",
    "  - Sinusoidal positional encoding\n",
    "  - Multi-head attention (6 heads, 6 layers)\n",
    "  - Nucleus sampling, top-k, temperature scaling\n",
    "- **Skills**: Deep Learning Architecture, NLP, Low-level Implementation\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcc4 Document Processing & NLP Engineering\n",
    "\n",
    "#### [NLP_Engineering/Document_Processing_Pipeline.ipynb](NLP_Engineering/Document_Processing_Pipeline.ipynb)\n",
    "**PDF Analysis with OpenAI Integration**\n",
    "\n",
    "- **Pipeline**: PDF Extraction \u2192 OpenAI Analysis \u2192 LaTeX Generation\n",
    "- **Technologies**: PyPDF2, OpenAI API, LaTeX, scikit-learn\n",
    "- **Highlights**:\n",
    "  - Automated exam question extraction\n",
    "  - AI-powered solution generation\n",
    "  - TF-IDF clustering for similarity detection\n",
    "  - Cost-optimized API batching\n",
    "- **Skills**: ETL Pipelines, API Integration, NLP, Document Generation\n",
    "\n",
    "---\n",
    "\n",
    "### \u2601\ufe0f Cloud Integration\n",
    "\n",
    "#### [Cloud_Integration/Azure_Face_DataLake.ipynb](Cloud_Integration/Azure_Face_DataLake.ipynb)\n",
    "**Azure Face API + Data Lake Pipeline**\n",
    "\n",
    "- **Architecture**: Blob Storage \u2192 Face API \u2192 Data Lake \u2192 Analytics\n",
    "- **Technologies**: Azure (Face API, Blob, Data Lake), Python, Streamlit\n",
    "- **Highlights**:\n",
    "  - Batch processing for 1000s of images\n",
    "  - Face detection + attribute extraction\n",
    "  - Tiered storage (hot/cool/archive)\n",
    "  - Cost optimization strategies\n",
    "- **Skills**: Cloud Architecture, Azure Services, Data Lake Design\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udda5\ufe0f Distributed Systems\n",
    "\n",
    "#### [Distributed_Systems/Hadoop_Docker_Setup.ipynb](Distributed_Systems/Hadoop_Docker_Setup.ipynb)\n",
    "**Containerized Hadoop Cluster**\n",
    "\n",
    "- **Stack**: Docker Compose \u2192 Hadoop \u2192 HDFS \u2192 YARN \u2192 MapReduce\n",
    "- **Technologies**: Docker, Hadoop, distributed computing\n",
    "- **Highlights**:\n",
    "  - Multi-node cluster orchestration\n",
    "  - HDFS with 3x replication\n",
    "  - MapReduce job execution\n",
    "  - Horizontal scaling patterns\n",
    "- **Skills**: DevOps, Infrastructure-as-Code, Big Data Architecture\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd25 Data Engineering: Spark & Kafka\n",
    "\n",
    "#### [PySpark/PySpark_Tutorial.ipynb](PySpark/PySpark_Tutorial.ipynb)\n",
    "**PySpark Data Processing**\n",
    "\n",
    "- **Focus**: Batch ETL, Spark SQL, DataFrames\n",
    "- **Highlights**: Window functions, UDFs, performance optimization\n",
    "\n",
    "#### [PySpark/Kafka_ETL/Kafka_ETL.ipynb](PySpark/Kafka_ETL/Kafka_ETL.ipynb)\n",
    "**Real-time Streaming with Kafka**\n",
    "\n",
    "- **Focus**: Structured Streaming, exactly-once semantics\n",
    "- **Highlights**: Checkpointing, fault tolerance, schema evolution\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca Causal Inference & Econometrics\n",
    "\n",
    "#### [IIEL_notebook/Spatial_Econometrics_Analysis.ipynb](IIEL_notebook/Spatial_Econometrics_Analysis.ipynb)\n",
    "**Spatial Econometrics & Treatment Effects**\n",
    "\n",
    "- **Focus**: Panel data, fixed effects, event studies\n",
    "- **Highlights**: Tkinter GUI, Folium maps, power simulations\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udee0\ufe0f Technology Stack\n",
    "\n",
    "### Programming & Frameworks\n",
    "```\n",
    "Python (Advanced)    \u2502 PyTorch \u2502 TensorFlow \u2502 scikit-learn\n",
    "PySpark (Production) \u2502 Pandas \u2502 NumPy \u2502 SQL\n",
    "```\n",
    "\n",
    "### Cloud & Infrastructure\n",
    "```\n",
    "Azure (Face API, Blob, Data Lake) \u2502 Docker \u2502 Kubernetes\n",
    "Kafka \u2502 Hadoop \u2502 HDFS \u2502 YARN\n",
    "```\n",
    "\n",
    "### Data Engineering\n",
    "```\n",
    "ETL Pipelines \u2502 Streaming (Kafka, Spark) \u2502 Batch Processing\n",
    "Data Modeling \u2502 Schema Design \u2502 Data Quality\n",
    "```\n",
    "\n",
    "### Machine Learning\n",
    "```\n",
    "Deep Learning \u2502 NLP (Transformers, LSTM) \u2502 Time Series\n",
    "Reinforcement Learning \u2502 Computer Vision \u2502 MLOps\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcc8 Project Metrics\n",
    "\n",
    "| Category | Metric | Value |\n",
    "|----------|--------|-------|\n",
    "| **Data Volume** | Max dataset processed | 100K+ rows |\n",
    "| **ML Models** | Parameters (largest) | ~10M (Transformer) |\n",
    "| **Streaming** | Throughput | Real-time (<200ms latency) |\n",
    "| **Cloud** | Images processed | 1000s/batch |\n",
    "| **Distributed** | Cluster nodes | 3-10 nodes (scalable) |\n",
    "| **API Integration** | Services | OpenAI, Azure, Binance |\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf93 Skills Demonstrated\n",
    "\n",
    "### Data Engineering (70%)\n",
    "- \u2705 ETL pipeline design and implementation\n",
    "- \u2705 Streaming data processing (Kafka, Spark Streaming)\n",
    "- \u2705 Batch processing optimization (PySpark)\n",
    "- \u2705 Data modeling and schema design\n",
    "- \u2705 Cloud data lakes and warehouses\n",
    "- \u2705 Distributed systems (Hadoop, HDFS)\n",
    "\n",
    "### Data Science (20%)\n",
    "- \u2705 Machine learning model development\n",
    "- \u2705 Deep learning (PyTorch, custom architectures)\n",
    "- \u2705 NLP and transformers\n",
    "- \u2705 Time series forecasting\n",
    "- \u2705 Statistical modeling and causal inference\n",
    "\n",
    "### Data Architecture (10%)\n",
    "- \u2705 System design for data platforms\n",
    "- \u2705 Infrastructure-as-Code (Docker, Kubernetes)\n",
    "- \u2705 Cloud architecture (Azure)\n",
    "- \u2705 Scalability patterns\n",
    "- \u2705 Cost optimization\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\ude80 Quick Start Guide\n",
    "\n",
    "### For Recruiters\n",
    "\n",
    "**Recommended Reading Order**:\n",
    "\n",
    "1. **Data Engineering Focus**: \n",
    "   - Start with `PySpark/Kafka_ETL/Kafka_ETL.ipynb` (streaming)\n",
    "   - Then `Distributed_Systems/Hadoop_Docker_Setup.ipynb` (architecture)\n",
    "   - Finally `Cloud_Integration/Azure_Face_DataLake.ipynb` (cloud)\n",
    "\n",
    "2. **Data Science Focus**:\n",
    "   - Start with `ML_Finance/GARCH_LSTM_Forecasting.ipynb` (production ML)\n",
    "   - Then `NLP/Custom_Transformer_Implementation.ipynb` (deep learning)\n",
    "   - Finally `ML_GameTheory/Poker_DeepRL.ipynb` (advanced AI)\n",
    "\n",
    "3. **Full-Stack Data Role**:\n",
    "   - Read all notebooks in order listed above\n",
    "\n",
    "### Running Notebooks\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install jupyter pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Launch Jupyter\n",
    "jupyter notebook\n",
    "\n",
    "# Navigate to INDEX.ipynb\n",
    "```\n",
    "\n",
    "**Note**: Some notebooks require external services (Azure, OpenAI API keys). Mock data is provided for demonstration.\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcde Contact & Links\n",
    "\n",
    "**Portfolio Repositories**:\n",
    "- [ffws_GARCHLSTM](https://github.com/anarcoiris/ffws_GARCHLSTM) - Financial ML\n",
    "- [DeepGamble](https://github.com/anarcoiris/DeepGamble) - Game Theory AI\n",
    "- [MiNiLLM](https://github.com/anarcoiris/MiNiLLM) - Transformer Implementation\n",
    "- [Examn_Xterminator](https://github.com/anarcoiris/Examn_Xterminator) - Document Processing\n",
    "- [FaceGUI](https://github.com/anarcoiris/FaceGUI) - Azure Cloud Integration\n",
    "- [docker-hadoop](https://github.com/anarcoiris/docker-hadoop) - Distributed Systems\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udfaf Why This Portfolio?\n",
    "\n",
    "### Production-Ready Code\n",
    "- \u2705 Error handling and validation\n",
    "- \u2705 Logging and monitoring\n",
    "- \u2705 Cost optimization\n",
    "- \u2705 Scalability patterns\n",
    "- \u2705 Documentation and testing\n",
    "\n",
    "### Real-World Complexity\n",
    "- \u2705 Multi-service integration\n",
    "- \u2705 Distributed systems\n",
    "- \u2705 Cloud architecture\n",
    "- \u2705 Data at scale (100K+ rows)\n",
    "- \u2705 Production deployment patterns\n",
    "\n",
    "### Breadth & Depth\n",
    "- \u2705 10+ technologies demonstrated\n",
    "- \u2705 End-to-end pipelines\n",
    "- \u2705 ML + Engineering + Cloud\n",
    "- \u2705 Batch + Streaming + Real-time\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcca Portfolio Statistics\n",
    "\n",
    "```\n",
    "Total Notebooks:        10+\n",
    "Lines of Code:          5000+ (across projects)\n",
    "Technologies:           15+ frameworks/tools\n",
    "Cloud Services:         3 (Azure, Binance, OpenAI)\n",
    "Distributed Nodes:      Up to 10 (Hadoop cluster)\n",
    "ML Model Parameters:    10M (largest model)\n",
    "Data Processed:         100K+ rows (batch), Real-time (streaming)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "*This portfolio showcases enterprise-grade data engineering and data science capabilities for production environments.*\n",
    "\n",
    "**Last Updated**: November 2025  \n",
    "**Status**: \u2705 All notebooks executable with demo data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio overview visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Skills distribution\n",
    "skills = ['Data Engineering', 'Machine Learning', 'Cloud/DevOps', 'Data Science', 'Distributed Systems']\n",
    "proficiency = [90, 85, 80, 85, 75]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Skills radar\n",
    "axes[0].barh(skills, proficiency, color='steelblue')\n",
    "axes[0].set_xlabel('Proficiency (%)')\n",
    "axes[0].set_title('Technical Skills Portfolio', fontweight='bold')\n",
    "axes[0].set_xlim(0, 100)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Project distribution\n",
    "categories = ['ML/DL', 'ETL/Streaming', 'Cloud', 'Distributed\\nSystems', 'NLP']\n",
    "project_counts = [3, 3, 1, 1, 2]\n",
    "axes[1].pie(project_counts, labels=categories, autopct='%1.0f%%', startangle=90)\n",
    "axes[1].set_title('Portfolio Coverage by Category', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Portfolio loaded successfully!\")\n",
    "print(\"Navigate to any notebook above to explore specific projects.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}