{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Data Engineering & Data Science Portfolio\n",
    "\n",
    "**Author**: Portfolio Showcase  \n",
    "**Last Updated**: 2025-11-29  \n",
    "**Target Roles**: Data Engineer | Data Scientist | Data Architect  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Overview\n",
    "\n",
    "This portfolio demonstrates **production-grade** data engineering, machine learning, and distributed systems expertise through real-world projects. All notebooks are executable and showcase end-to-end implementation from data ingestion to deployment.\n",
    "\n",
    "### üîë Key Competencies\n",
    "\n",
    "‚úÖ **Data Engineering**: ETL pipelines, streaming (Kafka), batch processing (PySpark)  \n",
    "‚úÖ **Machine Learning**: Deep learning (PyTorch), NLP, time series forecasting  \n",
    "‚úÖ **Cloud Architecture**: Azure integration, Data Lake, blob storage  \n",
    "‚úÖ **Distributed Systems**: Hadoop, HDFS, Docker, containerization  \n",
    "‚úÖ **Production Patterns**: Monitoring, error handling, cost optimization  \n",
    "\n",
    "---\n",
    "\n",
    "## üìö Portfolio Structure\n",
    "\n",
    "### ü§ñ Machine Learning & Finance\n",
    "\n",
    "#### [ML_Finance/GARCH_LSTM_Forecasting.ipynb](ML_Finance/GARCH_LSTM_Forecasting.ipynb)\n",
    "**Cryptocurrency Trading System with LSTM**\n",
    "\n",
    "- **Pipeline**: Kafka ‚Üí SQLite ‚Üí Feature Engineering ‚Üí LSTM\n",
    "- **Technologies**: PyTorch, Kafka, SQLite, Technical Analysis\n",
    "- **Highlights**: \n",
    "  - 50+ technical indicators (Fibonacci, RSI, ATR)\n",
    "  - Dual-output LSTM (price + volatility)\n",
    "  - Production daemon with paper/live trading\n",
    "  - Data leakage prevention (temporal splits)\n",
    "- **Skills**: ML Engineering, Financial Modeling, Streaming ETL\n",
    "\n",
    "---\n",
    "\n",
    "### üéÆ Game Theory & Reinforcement Learning\n",
    "\n",
    "#### [ML_GameTheory/Poker_DeepRL.ipynb](ML_GameTheory/Poker_DeepRL.ipynb)\n",
    "**Poker Strategy Analysis with Deep RL**\n",
    "\n",
    "- **Approach**: Game-theoretic AI, Nash equilibrium approximation\n",
    "- **Technologies**: Python, Deep Learning, Monte Carlo Simulation\n",
    "- **Highlights**:\n",
    "  - Self-attention for state representation\n",
    "  - Counterfactual regret minimization\n",
    "  - Monte Carlo equity calculation\n",
    "  - GTO strategy implementation\n",
    "- **Skills**: Reinforcement Learning, Game Theory, Statistical Simulation\n",
    "\n",
    "---\n",
    "\n",
    "### üß† NLP & Transformers\n",
    "\n",
    "#### [NLP/Custom_Transformer_Implementation.ipynb](NLP/Custom_Transformer_Implementation.ipynb)\n",
    "**Transformer Architecture from Scratch**\n",
    "\n",
    "- **Implementation**: Character-level language model (10M parameters)\n",
    "- **Technologies**: Python, NumPy, Deep Learning\n",
    "- **Highlights**:\n",
    "  - Self-attention mechanism with causal masking\n",
    "  - Sinusoidal positional encoding\n",
    "  - Multi-head attention (6 heads, 6 layers)\n",
    "  - Nucleus sampling, top-k, temperature scaling\n",
    "- **Skills**: Deep Learning Architecture, NLP, Low-level Implementation\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ Document Processing & NLP Engineering\n",
    "\n",
    "#### [NLP_Engineering/Document_Processing_Pipeline.ipynb](NLP_Engineering/Document_Processing_Pipeline.ipynb)\n",
    "**PDF Analysis with OpenAI Integration**\n",
    "\n",
    "- **Pipeline**: PDF Extraction ‚Üí OpenAI Analysis ‚Üí LaTeX Generation\n",
    "- **Technologies**: PyPDF2, OpenAI API, LaTeX, scikit-learn\n",
    "- **Highlights**:\n",
    "  - Automated exam question extraction\n",
    "  - AI-powered solution generation\n",
    "  - TF-IDF clustering for similarity detection\n",
    "  - Cost-optimized API batching\n",
    "- **Skills**: ETL Pipelines, API Integration, NLP, Document Generation\n",
    "\n",
    "---\n",
    "\n",
    "### ‚òÅÔ∏è Cloud Integration\n",
    "\n",
    "#### [Cloud_Integration/Azure_Face_DataLake.ipynb](Cloud_Integration/Azure_Face_DataLake.ipynb)\n",
    "**Azure Face API + Data Lake Pipeline**\n",
    "\n",
    "- **Architecture**: Blob Storage ‚Üí Face API ‚Üí Data Lake ‚Üí Analytics\n",
    "- **Technologies**: Azure (Face API, Blob, Data Lake), Python, Streamlit\n",
    "- **Highlights**:\n",
    "  - Batch processing for 1000s of images\n",
    "  - Face detection + attribute extraction\n",
    "  - Tiered storage (hot/cool/archive)\n",
    "  - Cost optimization strategies\n",
    "- **Skills**: Cloud Architecture, Azure Services, Data Lake Design\n",
    "\n",
    "---\n",
    "\n",
    "### üñ•Ô∏è Distributed Systems\n",
    "\n",
    "#### [Distributed_Systems/Hadoop_Docker_Setup.ipynb](Distributed_Systems/Hadoop_Docker_Setup.ipynb)\n",
    "**Containerized Hadoop Cluster**\n",
    "\n",
    "- **Stack**: Docker Compose ‚Üí Hadoop ‚Üí HDFS ‚Üí YARN ‚Üí MapReduce\n",
    "- **Technologies**: Docker, Hadoop, distributed computing\n",
    "- **Highlights**:\n",
    "  - Multi-node cluster orchestration\n",
    "  - HDFS with 3x replication\n",
    "  - MapReduce job execution\n",
    "  - Horizontal scaling patterns\n",
    "- **Skills**: DevOps, Infrastructure-as-Code, Big Data Architecture\n",
    "\n",
    "---\n",
    "\n",
    "### üî• Data Engineering: Spark & Kafka\n",
    "\n",
    "#### [PySpark/PySpak_Tutorial.ipynb](PySpark/PySpak_Tutorial.ipynb)\n",
    "**PySpark Data Processing**\n",
    "\n",
    "- **Focus**: Batch ETL, Spark SQL, DataFrames\n",
    "- **Highlights**: Window functions, UDFs, performance optimization\n",
    "\n",
    "#### [PySpark/Kafka_ETL/Kafka_ETL.ipynb](PySpark/Kafka_ETL/Kafka_ETL.ipynb)\n",
    "**Real-time Streaming with Kafka**\n",
    "\n",
    "- **Focus**: Structured Streaming, exactly-once semantics\n",
    "- **Highlights**: Checkpointing, fault tolerance, schema evolution\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Causal Inference & Econometrics\n",
    "\n",
    "#### [IIEL_notebook/notebook_IIEL.ipynb](IIEL_notebook/notebook_IIEL.ipynb)\n",
    "**Spatial Econometrics & Treatment Effects**\n",
    "\n",
    "- **Focus**: Panel data, fixed effects, event studies\n",
    "- **Highlights**: Tkinter GUI, Folium maps, power simulations\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Technology Stack\n",
    "\n",
    "### Programming & Frameworks\n",
    "```\n",
    "Python (Advanced)    ‚îÇ PyTorch ‚îÇ TensorFlow ‚îÇ scikit-learn\n",
    "PySpark (Production) ‚îÇ Pandas ‚îÇ NumPy ‚îÇ SQL\n",
    "```\n",
    "\n",
    "### Cloud & Infrastructure\n",
    "```\n",
    "Azure (Face API, Blob, Data Lake) ‚îÇ Docker ‚îÇ Kubernetes\n",
    "Kafka ‚îÇ Hadoop ‚îÇ HDFS ‚îÇ YARN\n",
    "```\n",
    "\n",
    "### Data Engineering\n",
    "```\n",
    "ETL Pipelines ‚îÇ Streaming (Kafka, Spark) ‚îÇ Batch Processing\n",
    "Data Modeling ‚îÇ Schema Design ‚îÇ Data Quality\n",
    "```\n",
    "\n",
    "### Machine Learning\n",
    "```\n",
    "Deep Learning ‚îÇ NLP (Transformers, LSTM) ‚îÇ Time Series\n",
    "Reinforcement Learning ‚îÇ Computer Vision ‚îÇ MLOps\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Project Metrics\n",
    "\n",
    "| Category | Metric | Value |\n",
    "|----------|--------|-------|\n",
    "| **Data Volume** | Max dataset processed | 100K+ rows |\n",
    "| **ML Models** | Parameters (largest) | ~10M (Transformer) |\n",
    "| **Streaming** | Throughput | Real-time (<200ms latency) |\n",
    "| **Cloud** | Images processed | 1000s/batch |\n",
    "| **Distributed** | Cluster nodes | 3-10 nodes (scalable) |\n",
    "| **API Integration** | Services | OpenAI, Azure, Binance |\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Skills Demonstrated\n",
    "\n",
    "### Data Engineering (70%)\n",
    "- ‚úÖ ETL pipeline design and implementation\n",
    "- ‚úÖ Streaming data processing (Kafka, Spark Streaming)\n",
    "- ‚úÖ Batch processing optimization (PySpark)\n",
    "- ‚úÖ Data modeling and schema design\n",
    "- ‚úÖ Cloud data lakes and warehouses\n",
    "- ‚úÖ Distributed systems (Hadoop, HDFS)\n",
    "\n",
    "### Data Science (20%)\n",
    "- ‚úÖ Machine learning model development\n",
    "- ‚úÖ Deep learning (PyTorch, custom architectures)\n",
    "- ‚úÖ NLP and transformers\n",
    "- ‚úÖ Time series forecasting\n",
    "- ‚úÖ Statistical modeling and causal inference\n",
    "\n",
    "### Data Architecture (10%)\n",
    "- ‚úÖ System design for data platforms\n",
    "- ‚úÖ Infrastructure-as-Code (Docker, Kubernetes)\n",
    "- ‚úÖ Cloud architecture (Azure)\n",
    "- ‚úÖ Scalability patterns\n",
    "- ‚úÖ Cost optimization\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Quick Start Guide\n",
    "\n",
    "### For Recruiters\n",
    "\n",
    "**Recommended Reading Order**:\n",
    "\n",
    "1. **Data Engineering Focus**: \n",
    "   - Start with `PySpark/Kafka_ETL/Kafka_ETL.ipynb` (streaming)\n",
    "   - Then `Distributed_Systems/Hadoop_Docker_Setup.ipynb` (architecture)\n",
    "   - Finally `Cloud_Integration/Azure_Face_DataLake.ipynb` (cloud)\n",
    "\n",
    "2. **Data Science Focus**:\n",
    "   - Start with `ML_Finance/GARCH_LSTM_Forecasting.ipynb` (production ML)\n",
    "   - Then `NLP/Custom_Transformer_Implementation.ipynb` (deep learning)\n",
    "   - Finally `ML_GameTheory/Poker_DeepRL.ipynb` (advanced AI)\n",
    "\n",
    "3. **Full-Stack Data Role**:\n",
    "   - Read all notebooks in order listed above\n",
    "\n",
    "### Running Notebooks\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install jupyter pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "# Launch Jupyter\n",
    "jupyter notebook\n",
    "\n",
    "# Navigate to INDEX.ipynb\n",
    "```\n",
    "\n",
    "**Note**: Some notebooks require external services (Azure, OpenAI API keys). Mock data is provided for demonstration.\n",
    "\n",
    "---\n",
    "\n",
    "## üìû Contact & Links\n",
    "\n",
    "**Portfolio Repositories**:\n",
    "- [ffws_GARCHLSTM](https://github.com/anarcoiris/ffws_GARCHLSTM) - Financial ML\n",
    "- [DeepGamble](https://github.com/anarcoiris/DeepGamble) - Game Theory AI\n",
    "- [MiNiLLM](https://github.com/anarcoiris/MiNiLLM) - Transformer Implementation\n",
    "- [Examn_Xterminator](https://github.com/anarcoiris/Examn_Xterminator) - Document Processing\n",
    "- [FaceGUI](https://github.com/anarcoiris/FaceGUI) - Azure Cloud Integration\n",
    "- [docker-hadoop](https://github.com/anarcoiris/docker-hadoop) - Distributed Systems\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Why This Portfolio?\n",
    "\n",
    "### Production-Ready Code\n",
    "- ‚úÖ Error handling and validation\n",
    "- ‚úÖ Logging and monitoring\n",
    "- ‚úÖ Cost optimization\n",
    "- ‚úÖ Scalability patterns\n",
    "- ‚úÖ Documentation and testing\n",
    "\n",
    "### Real-World Complexity\n",
    "- ‚úÖ Multi-service integration\n",
    "- ‚úÖ Distributed systems\n",
    "- ‚úÖ Cloud architecture\n",
    "- ‚úÖ Data at scale (100K+ rows)\n",
    "- ‚úÖ Production deployment patterns\n",
    "\n",
    "### Breadth & Depth\n",
    "- ‚úÖ 10+ technologies demonstrated\n",
    "- ‚úÖ End-to-end pipelines\n",
    "- ‚úÖ ML + Engineering + Cloud\n",
    "- ‚úÖ Batch + Streaming + Real-time\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Portfolio Statistics\n",
    "\n",
    "```\n",
    "Total Notebooks:        10+\n",
    "Lines of Code:          5000+ (across projects)\n",
    "Technologies:           15+ frameworks/tools\n",
    "Cloud Services:         3 (Azure, Binance, OpenAI)\n",
    "Distributed Nodes:      Up to 10 (Hadoop cluster)\n",
    "ML Model Parameters:    10M (largest model)\n",
    "Data Processed:         100K+ rows (batch), Real-time (streaming)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "*This portfolio showcases enterprise-grade data engineering and data science capabilities for production environments.*\n",
    "\n",
    "**Last Updated**: November 2025  \n",
    "**Status**: ‚úÖ All notebooks executable with demo data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio overview visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Skills distribution\n",
    "skills = ['Data Engineering', 'Machine Learning', 'Cloud/DevOps', 'Data Science', 'Distributed Systems']\n",
    "proficiency = [90, 85, 80, 85, 75]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Skills radar\n",
    "axes[0].barh(skills, proficiency, color='steelblue')\n",
    "axes[0].set_xlabel('Proficiency (%)')\n",
    "axes[0].set_title('Technical Skills Portfolio', fontweight='bold')\n",
    "axes[0].set_xlim(0, 100)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Project distribution\n",
    "categories = ['ML/DL', 'ETL/Streaming', 'Cloud', 'Distributed\\nSystems', 'NLP']\n",
    "project_counts = [3, 3, 1, 1, 2]\n",
    "axes[1].pie(project_counts, labels=categories, autopct='%1.0f%%', startangle=90)\n",
    "axes[1].set_title('Portfolio Coverage by Category', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Portfolio loaded successfully!\")\n",
    "print(\"Navigate to any notebook above to explore specific projects.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
